{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "2d-axis3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shalabh147/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/blob/master/2d_axis3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "tPWwetWkYVy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras import metrics\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import os\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "# from medpy.io import load\n",
        "import numpy as np\n",
        "\n",
        "#import cv2\n",
        "import nibabel as nib\n",
        "from PIL import Image\n",
        "\n",
        "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
        "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(input_mat)\n",
        "  if batch_norm:\n",
        "    X = BatchNormalization()(X)\n",
        " \n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(X)\n",
        "  if batch_norm:\n",
        "    X = BatchNormalization()(X)\n",
        " \n",
        "  X = Activation('relu')(X)\n",
        " \n",
        "  return X\n",
        "\n",
        "def Unet(input_img, n_filters = 32, dropout = 0.15, batch_norm = True):\n",
        "\n",
        "  c1 = conv_block(input_img,n_filters,3,batch_norm)\n",
        "  p1 = Conv2D(n_filters,kernel_size = (3,3), strides=2, padding = 'same' , kernel_initializer = 'he_normal')(c1)\n",
        "  p1 = Dropout(dropout)(p1)\n",
        " \n",
        "  c2 = conv_block(p1,n_filters*2,3,batch_norm);\n",
        "  p2 = Conv2D(n_filters,kernel_size = (3,3), strides=2 , padding = 'same' , kernel_initializer = 'he_normal')(c2)\n",
        "  p2 = Dropout(dropout)(p2)\n",
        "\n",
        "  c3 = conv_block(p2,n_filters*4,3,batch_norm);\n",
        "  p3 = Conv2D(n_filters,kernel_size = (3,3), strides=2 , padding = 'same' , kernel_initializer = 'he_normal')(c3)\n",
        "  p3 = Dropout(dropout)(p3)\n",
        " \n",
        "  c4 = conv_block(p3,n_filters*8,3,batch_norm);\n",
        "  p4 = Conv2D(n_filters,kernel_size = (3,3), strides=2 , padding = 'same' , kernel_initializer = 'he_normal')(c4)\n",
        "  p4 = Dropout(dropout)(p4)\n",
        " \n",
        "  c5 = conv_block(p4,n_filters*16,3,batch_norm);\n",
        "\n",
        "  u6 = Conv2DTranspose(n_filters*8, (3,3), strides=(2, 2), padding='same')(c5);\n",
        "  u6 = concatenate([u6,c4]);\n",
        "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
        "  c6 = Dropout(dropout)(c6)\n",
        "  u7 = Conv2DTranspose(n_filters*4,(3,3),strides = (2,2) , padding= 'same')(c6);\n",
        "\n",
        "  u7 = concatenate([u7,c3]);\n",
        "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
        "  c7 = Dropout(dropout)(c7)\n",
        "  u8 = Conv2DTranspose(n_filters*2,(3,3),strides = (2,2) , padding='same')(c7);\n",
        "  u8 = concatenate([u8,c2]);\n",
        "\n",
        "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
        "  c8 = Dropout(dropout)(c8)\n",
        "  u9 = Conv2DTranspose(n_filters,(3,3),strides = (2,2) , padding='same')(c8);\n",
        "\n",
        "  u9 = concatenate([u9,c1]);\n",
        "\n",
        "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
        "  outputs = Conv2D(2, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = Model(inputs=input_img, outputs=outputs)\n",
        "\n",
        "  return model\n",
        "\n",
        "'''\n",
        "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
        "  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)\n",
        "  if batch_norm:\n",
        "    X = BatchNormalization()(X)\n",
        " \n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)\n",
        "  if batch_norm:\n",
        "    X = BatchNormalization()(X)\n",
        " \n",
        "  X = Activation('relu')(X)\n",
        " \n",
        "  return X\n",
        "\n",
        "\n",
        "def Unet_3d(input_img, n_filters = 18, dropout = 0.2, batch_norm = True):\n",
        "\n",
        "  c1 = conv_block(input_img,n_filters,3,batch_norm)\n",
        "  p1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(c1)\n",
        "  p1 = Dropout(dropout)(p1)\n",
        " \n",
        "  c2 = conv_block(p1,n_filters*2,3,batch_norm);\n",
        "  p2 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c2)\n",
        "  p2 = Dropout(dropout)(p2)\n",
        "\n",
        "  c3 = conv_block(p2,n_filters*4,3,batch_norm);\n",
        "  p3 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c3)\n",
        "  p3 = Dropout(dropout)(p3)\n",
        " \n",
        "  c4 = conv_block(p3,n_filters*8,3,batch_norm);\n",
        "  p4 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c4)\n",
        "  p4 = Dropout(dropout)(p4)\n",
        " \n",
        "  c5 = conv_block(p4,n_filters*16,3,batch_norm);\n",
        "\n",
        "  u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(c5);\n",
        "  u6 = concatenate([u6,c4]);\n",
        "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
        "  c6 = Dropout(dropout)(c6)\n",
        "  u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c6);\n",
        "\n",
        "  u7 = concatenate([u7,c3]);\n",
        "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
        "  c7 = Dropout(dropout)(c7)\n",
        "  u8 = Conv3DTranspose(n_filters*2,(3,3,3),strides = (2,2,2) , padding='same')(c7);\n",
        "  u8 = concatenate([u8,c2]);\n",
        "\n",
        "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
        "  c8 = Dropout(dropout)(c8)\n",
        "  u9 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding='same')(c8);\n",
        "\n",
        "  u9 = concatenate([u9,c1]);\n",
        "\n",
        "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
        "  outputs = Conv3D(4, (1, 1,1), activation='softmax')(c9)\n",
        "\n",
        "  model = Model(inputs=input_img, outputs=outputs)\n",
        "\n",
        "  return model\n",
        "'''\n",
        "\n",
        "def standardize(image):\n",
        "\n",
        "  standardized_image = np.zeros(image.shape)\n",
        "\n",
        "  #\n",
        " \n",
        "      # iterate over the `z` dimension\n",
        "  for z in range(image.shape[2]):\n",
        "      # get a slice of the image\n",
        "      # at channel c and z-th dimension `z`\n",
        "      image_slice = image[:,:,z]\n",
        "\n",
        "      # subtract the mean from image_slice\n",
        "      centered = image_slice - np.mean(image_slice)\n",
        "     \n",
        "      # divide by the standard deviation (only if it is different from zero)\n",
        "      if(np.std(centered)!=0):\n",
        "          centered = centered/np.std(centered)\n",
        "\n",
        "      # update  the slice of standardized image\n",
        "      # with the scaled centered and scaled image\n",
        "      standardized_image[:, :, z] = centered\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return standardized_image\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
        "    \"\"\"\n",
        "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
        "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
        "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
        "   \n",
        "    \"\"\"\n",
        "    axis = (0,1,2)\n",
        "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
        "    return K.mean((dice_numerator)/(dice_denominator))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "input_img = Input((240,240,4))\n",
        "model = Unet(input_img,32,0.15,True)\n",
        "learning_rate = 0.00095\n",
        "#epochs = 5000\n",
        "decay_rate = 0.0000002\n",
        "model.compile(optimizer=Adam(lr=learning_rate, decay = decay_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "path = '../input/vs-brats2018/miccai_brats_2018_data_training/HGG'\n",
        "all_images = os.listdir(path)\n",
        "#print(len(all_images))\n",
        "all_images.sort()\n",
        "data = np.zeros((240,240,155,4))\n",
        "image_data2=np.zeros((240,240,155))\n",
        "loss_hist = []\n",
        "accu_hist = []\n",
        "epoch_wise_loss = []\n",
        "epoch_wise_accu = []\n",
        "for epochs in range(49):\n",
        "  epoch_loss = 0\n",
        "  epoch_accu = 0\n",
        "  for image_num in range(180):\n",
        "    x_to = []\n",
        "    y_to = []\n",
        "    print(epochs)\n",
        "    print(image_num)\n",
        "\n",
        "# data preprocessing starts here\n",
        "\n",
        "    x = all_images[image_num]\n",
        "    print(x)\n",
        "    folder_path = path + '/' + x;\n",
        "    modalities = os.listdir(folder_path)\n",
        "    modalities.sort()\n",
        "    #data = []\n",
        "    w = 0\n",
        "    for j in range(len(modalities)):\n",
        "      #print(modalities[j])\n",
        "     \n",
        "      image_path = folder_path + '/' + modalities[j]\n",
        "      if not(image_path.find('seg.nii') == -1):\n",
        "        img = nib.load(image_path);\n",
        "        image_data2 = img.get_data()\n",
        "        image_data2 = np.asarray(image_data2)\n",
        "        print(\"Entered ground truth\")\n",
        "      else:\n",
        "        img = nib.load(image_path);\n",
        "        image_data = img.get_data()\n",
        "        image_data = np.asarray(image_data)\n",
        "        image_data = standardize(image_data)\n",
        "        data[:,:,:,w] = image_data\n",
        "        print(\"Entered modality\")\n",
        "        w = w+1\n",
        "     \n",
        "    print(data.shape)\n",
        "    print(image_data2.shape)  \n",
        "   \n",
        "    '''\n",
        "    reshaped_data=data[56:184,75:203,13:141,:]\n",
        "    reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
        "    reshaped_image_data2=image_data2[56:184,75:203,13:141]\n",
        "\n",
        "       \n",
        "    reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
        "    reshaped_image_data2[reshaped_image_data2==4] = 3\n",
        "    hello = reshaped_image_data2.flatten()\n",
        "    #y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
        "    print(reshaped_image_data2.shape)\n",
        "    #print(hello[hello==3].shape)\n",
        "    print(\"Number of classes\",np.unique(hello))\n",
        "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
        "    print(class_weights)\n",
        "   \n",
        "   \n",
        "    '''\n",
        "   \n",
        "   \n",
        "    for slice_no in range(0,155):\n",
        "        a = slice_no\n",
        "        X = data[:,:,slice_no,:]\n",
        "\n",
        "        Y = image_data2[:,:,slice_no]\n",
        "        # imgplot = plt.imshow(X[:,:,2])\n",
        "        # plt.show(block=False)\n",
        "        # plt.pause(0.3)\n",
        "        # plt.close()\n",
        "\n",
        "        # imgplot = plt.imshow(Y)\n",
        "        # plt.show(block=False)\n",
        "        # plt.pause(0.3)\n",
        "        # plt.close()\n",
        "\n",
        "        if(X.any()!=0 and Y.any()!=0 and len(np.unique(Y)) == 4):\n",
        "          #print(slice_no)\n",
        "          x_to.append(X)\n",
        "          y_to.append(Y)\n",
        "          if len(y_to)>=50:\n",
        "                break;\n",
        "\n",
        "        #reshaped_image_data2 = to_categorical(reshaped_image_data2, num_classes = 4)\n",
        "\n",
        "        #print(reshaped_data.shape)\n",
        "        #print(reshaped_image_data2.shape)\n",
        "        #print(type(reshaped_data))\n",
        "\n",
        "    x_to = np.asarray(x_to)\n",
        "    y_to = np.asarray(y_to)\n",
        "    print(x_to.shape)\n",
        "    print(y_to.shape)\n",
        "\n",
        " \n",
        "    y_to[y_to==4] = 1        \n",
        "    #y_to = one_hot_encode(y_to)\n",
        "    y_to[y_to==2] = 1\n",
        "    y_to[y_to==1] = 1\n",
        "    y_to[y_to==0] = 0\n",
        "    print(y_to.shape)\n",
        "   \n",
        "   \n",
        "    from sklearn.utils import shuffle\n",
        "    x_to,y_to = shuffle(x_to,y_to)\n",
        "   \n",
        "    hello = y_to.flatten()\n",
        "    #print(hello[hello==3].shape)\n",
        "    print(\"Number of classes\",np.unique(hello))\n",
        "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
        " \n",
        "    #class_weights.insert(3,0)\n",
        "    print(\"class_weights\",class_weights)\n",
        "\n",
        "\n",
        "    y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
        "    history = model.fit(x=x_to,y=y_to, epochs = 1 , batch_size = 50 ,class_weight = class_weights)\n",
        "    print(history.history['loss'])\n",
        "    epoch_loss += history.history['loss'][0]\n",
        "    epoch_accu += history.history['dice_coef'][0]\n",
        "   \n",
        "    loss_hist.append(history.history['loss'])\n",
        "    accu_hist.append(history.history['dice_coef'])\n",
        " \n",
        "  model.save('../working/2d_model_axis3.h5')\n",
        "  epoch_loss = epoch_loss/180\n",
        "  epoch_accu = epoch_accu/180\n",
        "\n",
        "  epoch_wise_loss.append(epoch_loss)\n",
        "  epoch_wise_accu.append(epoch_accu)\n",
        " \n",
        "  plt.plot(epoch_wise_loss)\n",
        "  plt.title('Model_loss vs epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('epochs')\n",
        "  s = '../working/epochwise_loss_' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        " \n",
        "  plt.plot(epoch_wise_accu)\n",
        "  plt.title('Model_Accuracy vs epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('epochs')\n",
        "  s = '../working/epochwise_accu_' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "   \n",
        "  plt.plot(accu_hist)\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  s = '../working/accuracy_plot_' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "   \n",
        "  plt.plot(loss_hist)\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  s = '../working/loss_plot_' + str(epochs)\n",
        "  plt.savefig(s)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "model.save('../working/2d_model_axis3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "MhmlXN2XYVy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}